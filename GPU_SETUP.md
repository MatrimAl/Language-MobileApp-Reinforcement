# ğŸš€ GPU EÄŸitim Kurulum Rehberi

## ğŸ“‹ Durum KontrolÃ¼

### Mevcut Durum
Åu anda sistem **CPU modunda** Ã§alÄ±ÅŸÄ±yor. GPU kullanÄ±mÄ± iÃ§in CUDA destekli PyTorch gerekli.

### GPU KontrolÃ¼
```powershell
cd backend
python -c "import torch; print('CUDA:', torch.cuda.is_available())"
```

## ğŸ¯ GPU Kurulum AdÄ±mlarÄ±

### 1. NVIDIA GPU KontrolÃ¼
BilgisayarÄ±nÄ±zda NVIDIA GPU olup olmadÄ±ÄŸÄ±nÄ± kontrol edin:
```powershell
nvidia-smi
```

**EÄŸer GPU varsa:** âœ… Devam edin  
**EÄŸer GPU yoksa:** âš ï¸ CPU modunda Ã§alÄ±ÅŸmaya devam edebilirsiniz

**CUDA Versiyonunuzu Kontrol Edin:**
```powershell
nvcc --version
# veya
nvidia-smi
```
Bu sistemde **CUDA 11.8** kullanÄ±lÄ±yor.

### 2. CUDA Toolkit (Zaten Kurulu)
âœ… CUDA 11.8 sisteminizde mevcut - ek kurulum gerekmez!

### 3. PyTorch GPU Kurulumu

#### Otomatik Kurulum (Ã–nerilen)
```powershell
cd backend
.\install_pytorch_gpu.ps1
```

#### Manuel Kurulum
```powershell
cd backend

# Mevcut PyTorch'u kaldÄ±r
pip uninstall -y torch torchvision torchaudio

# GPU versiyonunu kur (CUDA 11.8 - SÄ°ZÄ°N VERSÄ°YONUNUZ)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# DoÄŸrulama
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None')"
```

**Not:** CUDA 11.8 kullanÄ±yorsunuz, bu yÃ¼zden `cu118` index'ini kullanÄ±n.

### 4. Backend'i Yeniden BaÅŸlat
```powershell
cd backend
python main.py
```

GPU algÄ±landÄ±ÄŸÄ±nda ÅŸu mesajÄ± gÃ¶receksiniz:
```
ğŸš€ GPU Training Enabled!
   â”œâ”€ Device: NVIDIA GeForce RTX 3060 (veya sizin GPU'nuz)
   â”œâ”€ Memory: 12.00 GB
   â””â”€ CUDA Version: 11.8
```

## ğŸ“Š GPU Performans FarkÄ±

### EÄŸitim HÄ±zÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Ã–zellik | CPU | GPU (RTX 3060) | GPU (RTX 4090) |
|---------|-----|----------------|----------------|
| 50 Episode | ~30 saniye | ~5-8 saniye | ~2-3 saniye |
| 500 Episode | ~5 dakika | ~50-80 saniye | ~20-30 saniye |
| Batch Size | 32 | 64-128 | 256-512 |

### Ã–nerilen Ayarlar

**CPU iÃ§in:**
```python
batch_size = 32
memory_size = 10000
```

**GPU iÃ§in:**
```python
batch_size = 128  # veya 256
memory_size = 50000
```

## ğŸ” GPU Ä°zleme

### API Endpoint
```bash
GET http://localhost:8000/api/rl/device/info
```

**YanÄ±t (GPU ile):**
```json
{
  "agent_loaded": true,
  "device_type": "cuda",
  "is_cuda": true,
  "gpu_name": "NVIDIA GeForce RTX 3060",
  "gpu_count": 1,
  "cuda_version": "11.8",
  "memory_allocated_mb": 45.2,
  "memory_reserved_mb": 128.0,
  "memory_total_gb": 12.0
}
```

### Python Kodu
```python
from dqn_agent import DQNAgent

agent = DQNAgent()
device_info = agent.get_device_info()
print(device_info)
```

## âš™ï¸ GeliÅŸmiÅŸ Ayarlar

### Mixed Precision Training (Opsiyonel)
Daha hÄ±zlÄ± eÄŸitim iÃ§in mixed precision kullanabilirsiniz:

```python
# dqn_agent.py dosyasÄ±na eklenebilir
from torch.cuda.amp import autocast, GradScaler

# Training loop iÃ§inde
scaler = GradScaler()

with autocast():
    q_values = model(states)
    loss = criterion(q_values, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### Multi-GPU (Gelecek Ã–zellik)
Birden fazla GPU iÃ§in DataParallel kullanÄ±labilir:

```python
if torch.cuda.device_count() > 1:
    self.model = nn.DataParallel(self.model)
```

## ğŸ› Sorun Giderme

### "CUDA out of memory" HatasÄ±
```python
# Batch size'Ä± azalt
agent = DQNAgent(batch_size=32)  # veya 16

# Veya memory'yi temizle
torch.cuda.empty_cache()
```

### CUDA SÃ¼rÃ¼m UyumsuzluÄŸu
```powershell
# PyTorch'un desteklediÄŸi CUDA versiyonunu kontrol et
python -c "import torch; print(torch.version.cuda)"

# CUDA 11.8 iÃ§in (SÄ°ZÄ°N VERSÄ°YONUNUZ):
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### GPU AlgÄ±lanmÄ±yor
1. NVIDIA sÃ¼rÃ¼cÃ¼sÃ¼nÃ¼ gÃ¼ncelleyin
2. CUDA Toolkit'i yeniden kurun
3. PyTorch'u doÄŸru CUDA versiyonu ile kurun
4. BilgisayarÄ± yeniden baÅŸlatÄ±n

## ğŸ“ˆ Benchmark

### Test Scripti
```python
import time
import torch
from dqn_agent import DQNAgent
from rl_environment import LanguageLearningEnv

agent = DQNAgent()
env = LanguageLearningEnv()

start = time.time()

# 100 episode eÄŸitim
for episode in range(100):
    state = env.reset()
    done = False
    
    while not done:
        action = agent.act(state)
        next_state, reward, done, _ = env.step(action)
        agent.remember(state, action, reward, next_state, done)
        state = next_state
        
        if len(agent.memory) > agent.batch_size:
            agent.replay()

end = time.time()
print(f"SÃ¼re: {end - start:.2f} saniye")
print(f"Episode baÅŸÄ±na: {(end - start) / 100:.2f} saniye")
```

## ğŸ“ Tez Sunumu Ä°Ã§in

GPU kullanÄ±mÄ±nÄ± gÃ¶stermek iÃ§in:

1. **Ã–ncesi-SonrasÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±**
   - CPU ile eÄŸitim sÃ¼resi
   - GPU ile eÄŸitim sÃ¼resi
   - HÄ±z kazancÄ± (Ã¶rn: 5x daha hÄ±zlÄ±)

2. **GPU KullanÄ±m Grafikleri**
   - Dashboard'a `GET /api/rl/device/info` endpoint'inden veri Ã§ek
   - Memory kullanÄ±mÄ±nÄ± gÃ¶ster
   - Batch processing hÄ±zÄ±nÄ± vurgula

3. **Teknik Detaylar**
   - PyTorch + CUDA
   - Automatic device detection
   - Batch parallelization
   - Tensor operations on GPU

## ğŸ“š Ek Kaynaklar

- [PyTorch CUDA Docs](https://pytorch.org/docs/stable/cuda.html)
- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)
- [GPU Optimization Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)

---

**Not:** GPU olmadan da sistem tamamen Ã§alÄ±ÅŸÄ±r. GPU sadece eÄŸitim hÄ±zÄ±nÄ± artÄ±rÄ±r, sonuÃ§larÄ± etkilemez.
